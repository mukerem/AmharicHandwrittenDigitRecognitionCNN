{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mukerem/AmharicHandwrittenDigitRecognitionCNN/blob/main/Handwritten_Amharic_Digit_Recognition_Using_Deep_Learning-17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "29kuFJREaKYO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8834e6ac-6e72-433e-cd64-ac035ce47751"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceCPcifFah1-"
      },
      "source": [
        "# **Load library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmIQsuCTbSBd"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/gdrive/MyDrive/PreProcessV1.zip' -d \"/content/gdrive/MyDrive/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "UcKozwcMZzr6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "\n",
        "config = tf.compat.v1.ConfigProto( device_count = {'GPU': 1 , 'CPU': 56} ) \n",
        "sess = tf.compat.v1.Session(config=config) \n",
        "K.set_session(sess)\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaJv2RwyRfCN",
        "outputId": "1dbe5365-9f13-4195-e8a4-97a8317163cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/PreProcessV1\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive/PreProcessV1/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "i0pycJHOZS1n"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "img_height = 32\n",
        "img_width = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "QPzXdMv3cE5M"
      },
      "outputs": [],
      "source": [
        "data_dir = \"/content/gdrive/MyDrive/PreProcessV1/\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **keras**\n"
      ],
      "metadata": {
        "id": "sV3b0cetmmDq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9pKCR0DcEtS",
        "outputId": "a0afde33-c3e2-4a9c-d3b0-8237f07984ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 51952 files belonging to 20 classes.\n",
            "Using 41562 files for training.\n"
          ]
        }
      ],
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  color_mode=\"grayscale\",\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53UWblhpdZ95",
        "outputId": "6521f15a-876e-4b34-febc-c539c71616f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 51952 files belonging to 20 classes.\n",
            "Using 10390 files for validation.\n"
          ]
        }
      ],
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  color_mode=\"grayscale\",\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "CzBg_kpbeIVB"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "            keras.Input(shape = (32, 32, 1)),\n",
        "            layers.Conv2D(32, 3, padding = 'same', activation = 'relu', name=\"Conv1\"),\n",
        "            layers.Conv2D(32, 3, padding = 'same', activation = 'relu', name=\"Conv2\"),\n",
        "            layers.Conv2D(32, 3, padding = 'same', activation = 'relu', name=\"Conv3\"),\n",
        "            layers.MaxPooling2D(name=\"Maxpool1\"),\n",
        "            layers.Dropout(0.25, input_shape=(2,)),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv4\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv5\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv6\"),\n",
        "            layers.MaxPooling2D(name=\"Maxpool2\"),\n",
        "            layers.Dropout(0.25, input_shape=(2,)),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv7\"),\n",
        "            layers.MaxPooling2D(name=\"Maxpool3\"),\n",
        "            layers.Dropout(0.25, input_shape=(2,)),\n",
        "            layers.Conv2D(128, 3, padding = 'same', activation = 'relu', name=\"Conv8\"),\n",
        "            layers.Flatten(name=\"Flatten1\"),\n",
        "            layers.Dense(128, activation = 'relu', name=\"Dense1\"),\n",
        "            layers.Dense(20, activation = 'softmax', name=\"Dense2\"),\n",
        "])"
      ],
      "metadata": {
        "id": "piJRCwqKm_vm"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APq2vCdU4kV8",
        "outputId": "6d8435a8-888e-474e-a9fa-4ba1c77ffa28"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Conv1 (Conv2D)              (None, 32, 32, 32)        320       \n",
            "                                                                 \n",
            " Conv2 (Conv2D)              (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " Conv3 (Conv2D)              (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " Maxpool1 (MaxPooling2D)     (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " Conv4 (Conv2D)              (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " Conv5 (Conv2D)              (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " Conv6 (Conv2D)              (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " Maxpool2 (MaxPooling2D)     (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " Conv7 (Conv2D)              (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " Maxpool3 (MaxPooling2D)     (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " Conv8 (Conv2D)              (None, 4, 4, 128)         73856     \n",
            "                                                                 \n",
            " Flatten1 (Flatten)          (None, 2048)              0         \n",
            "                                                                 \n",
            " Dense1 (Dense)              (None, 128)               262272    \n",
            "                                                                 \n",
            " Dense2 (Dense)              (None, 20)                2580      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 486,804\n",
            "Trainable params: 486,804\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nadam = tf.keras.optimizers.Nadam(\n",
        "    learning_rate=1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Nadam\"\n",
        ")"
      ],
      "metadata": {
        "id": "Gc-YimqF4TBW"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adamax = tf.keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)"
      ],
      "metadata": {
        "id": "ho7RD9fBVGmX"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = tf.keras.optimizers.SGD(\n",
        "    learning_rate=0.01,\n",
        "    momentum=0.0,\n",
        "    nesterov=False,\n",
        "    name='SGD',\n",
        ")"
      ],
      "metadata": {
        "id": "QzwfU5NdVK0f"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adam =  keras.optimizers.Adam(lr = 1e-3)"
      ],
      "metadata": {
        "id": "Q7vCTvZQ4XKY"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "        loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "        optimizer = adam,\n",
        "        metrics = ['acc'],\n",
        ")"
      ],
      "metadata": {
        "id": "PNubZ416Sviu"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "MwlAQESPeIOd"
      },
      "outputs": [],
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', patience = 2, verbose = 1, factor = 0.5, min_lr = 1e-7)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(\"best_model_epoch_{epoch:02d}-{val_loss:.2f}.h5\", monitor='val_acc', verbose=1,\n",
        "    save_best_only=True, mode='auto', period=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ssxru6PafEl",
        "outputId": "a194a496-9ff4-4a79-8fcb-57b394a5bc90"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ob_iP5OgeIMD",
        "outputId": "1591c27d-55d3-4e29-abd6-a951494c0b56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 1.5771 - acc: 0.5188\n",
            "Epoch 1: val_acc improved from -inf to 0.84033, saving model to best_model_epoch_01-0.60.h5\n",
            "1299/1299 [==============================] - 28s 21ms/step - loss: 1.5757 - acc: 0.5193 - val_loss: 0.5982 - val_acc: 0.8403 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.5307 - acc: 0.8547\n",
            "Epoch 2: val_acc improved from 0.84033 to 0.90202, saving model to best_model_epoch_02-0.38.h5\n",
            "1299/1299 [==============================] - 27s 20ms/step - loss: 0.5307 - acc: 0.8547 - val_loss: 0.3786 - val_acc: 0.9020 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.3921 - acc: 0.8965\n",
            "Epoch 3: val_acc improved from 0.90202 to 0.91540, saving model to best_model_epoch_03-0.34.h5\n",
            "1299/1299 [==============================] - 27s 21ms/step - loss: 0.3922 - acc: 0.8964 - val_loss: 0.3426 - val_acc: 0.9154 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.3354 - acc: 0.9120\n",
            "Epoch 4: val_acc improved from 0.91540 to 0.93032, saving model to best_model_epoch_04-0.29.h5\n",
            "1299/1299 [==============================] - 27s 20ms/step - loss: 0.3355 - acc: 0.9120 - val_loss: 0.2884 - val_acc: 0.9303 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.3016 - acc: 0.9202\n",
            "Epoch 5: val_acc did not improve from 0.93032\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.3016 - acc: 0.9202 - val_loss: 0.3134 - val_acc: 0.9254 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.2706 - acc: 0.9281\n",
            "Epoch 6: val_acc improved from 0.93032 to 0.93657, saving model to best_model_epoch_06-0.26.h5\n",
            "1299/1299 [==============================] - 27s 21ms/step - loss: 0.2708 - acc: 0.9281 - val_loss: 0.2632 - val_acc: 0.9366 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.2688 - acc: 0.9292\n",
            "Epoch 7: val_acc did not improve from 0.93657\n",
            "1299/1299 [==============================] - 27s 20ms/step - loss: 0.2688 - acc: 0.9292 - val_loss: 0.2857 - val_acc: 0.9348 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.2519 - acc: 0.9347\n",
            "Epoch 8: val_acc improved from 0.93657 to 0.94139, saving model to best_model_epoch_08-0.24.h5\n",
            "1299/1299 [==============================] - 27s 21ms/step - loss: 0.2521 - acc: 0.9346 - val_loss: 0.2417 - val_acc: 0.9414 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.2479 - acc: 0.9345\n",
            "Epoch 9: val_acc improved from 0.94139 to 0.94533, saving model to best_model_epoch_09-0.25.h5\n",
            "1299/1299 [==============================] - 27s 21ms/step - loss: 0.2478 - acc: 0.9345 - val_loss: 0.2494 - val_acc: 0.9453 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.2346 - acc: 0.9380\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 10: val_acc did not improve from 0.94533\n",
            "1299/1299 [==============================] - 27s 21ms/step - loss: 0.2347 - acc: 0.9380 - val_loss: 0.2513 - val_acc: 0.9443 - lr: 0.0010\n",
            "Epoch 11/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.1738 - acc: 0.9538\n",
            "Epoch 11: val_acc improved from 0.94533 to 0.95284, saving model to best_model_epoch_11-0.21.h5\n",
            "1299/1299 [==============================] - 27s 20ms/step - loss: 0.1739 - acc: 0.9539 - val_loss: 0.2118 - val_acc: 0.9528 - lr: 5.0000e-04\n",
            "Epoch 12/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.1576 - acc: 0.9580\n",
            "Epoch 12: val_acc improved from 0.95284 to 0.95313, saving model to best_model_epoch_12-0.21.h5\n",
            "1299/1299 [==============================] - 27s 21ms/step - loss: 0.1575 - acc: 0.9580 - val_loss: 0.2096 - val_acc: 0.9531 - lr: 5.0000e-04\n",
            "Epoch 13/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.1502 - acc: 0.9600\n",
            "Epoch 13: val_acc did not improve from 0.95313\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.1501 - acc: 0.9601 - val_loss: 0.2292 - val_acc: 0.9529 - lr: 5.0000e-04\n",
            "Epoch 14/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.1440 - acc: 0.9603\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 14: val_acc did not improve from 0.95313\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.1439 - acc: 0.9603 - val_loss: 0.2280 - val_acc: 0.9517 - lr: 5.0000e-04\n",
            "Epoch 15/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.1131 - acc: 0.9686\n",
            "Epoch 15: val_acc improved from 0.95313 to 0.95515, saving model to best_model_epoch_15-0.22.h5\n",
            "1299/1299 [==============================] - 27s 21ms/step - loss: 0.1131 - acc: 0.9686 - val_loss: 0.2184 - val_acc: 0.9551 - lr: 2.5000e-04\n",
            "Epoch 16/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.1005 - acc: 0.9719\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 16: val_acc improved from 0.95515 to 0.95630, saving model to best_model_epoch_16-0.22.h5\n",
            "1299/1299 [==============================] - 27s 21ms/step - loss: 0.1004 - acc: 0.9719 - val_loss: 0.2177 - val_acc: 0.9563 - lr: 2.5000e-04\n",
            "Epoch 17/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.0842 - acc: 0.9755\n",
            "Epoch 17: val_acc improved from 0.95630 to 0.95659, saving model to best_model_epoch_17-0.22.h5\n",
            "1299/1299 [==============================] - 27s 21ms/step - loss: 0.0842 - acc: 0.9755 - val_loss: 0.2208 - val_acc: 0.9566 - lr: 1.2500e-04\n",
            "Epoch 18/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.0809 - acc: 0.9758\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 18: val_acc did not improve from 0.95659\n",
            "1299/1299 [==============================] - 27s 21ms/step - loss: 0.0810 - acc: 0.9757 - val_loss: 0.2206 - val_acc: 0.9561 - lr: 1.2500e-04\n",
            "Epoch 19/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.0726 - acc: 0.9790\n",
            "Epoch 19: val_acc improved from 0.95659 to 0.95765, saving model to best_model_epoch_19-0.22.h5\n",
            "1299/1299 [==============================] - 27s 20ms/step - loss: 0.0726 - acc: 0.9790 - val_loss: 0.2190 - val_acc: 0.9577 - lr: 6.2500e-05\n",
            "Epoch 20/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.0675 - acc: 0.9796\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\n",
            "Epoch 20: val_acc did not improve from 0.95765\n",
            "1299/1299 [==============================] - 27s 21ms/step - loss: 0.0675 - acc: 0.9796 - val_loss: 0.2215 - val_acc: 0.9575 - lr: 6.2500e-05\n",
            "Epoch 21/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9811\n",
            "Epoch 21: val_acc improved from 0.95765 to 0.95813, saving model to best_model_epoch_21-0.22.h5\n",
            "1299/1299 [==============================] - 27s 21ms/step - loss: 0.0638 - acc: 0.9811 - val_loss: 0.2209 - val_acc: 0.9581 - lr: 3.1250e-05\n",
            "Epoch 22/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.0636 - acc: 0.9814"
          ]
        }
      ],
      "source": [
        "classifier = model.fit(train_ds, batch_size = batch_size, \n",
        "                                 epochs = 30,\n",
        "                                 callbacks=[reduce_lr, checkpoint],\n",
        "                                 validation_data = val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ghprZPhjGt4K"
      },
      "outputs": [],
      "source": [
        "# model.save('/content/gdrive/MyDrive/30-epoch-val-acc-9589-lr-1e-3-two-dropout-2e-1-batch-32-adam.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data Augmentation**\n"
      ],
      "metadata": {
        "id": "c1fWmsuFZG65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "   rescale=1.0 / 255,\n",
        "   rotation_range=30,\n",
        "   width_shift_range=0.2,\n",
        "   height_shift_range=0.2,\n",
        "   vertical_flip=True,\n",
        ")"
      ],
      "metadata": {
        "id": "XERb7b_DO3jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EavxErWdZxYL",
        "outputId": "ffd6a80a-f1f9-46e3-b7cc-228ea6efb62d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 51952 images belonging to 20 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjIuEERLdM2a",
        "outputId": "a443ce00-246c-4668-807e-6f100051515a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.preprocessing.image.DirectoryIterator at 0x7f843b0df910>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "   rescale=1.0 / 255,\n",
        "   rotation_range=30,\n",
        "   width_shift_range=0.2,\n",
        "   height_shift_range=0.2,\n",
        "   vertical_flip=True,\n",
        ")"
      ],
      "metadata": {
        "id": "Nqk5FL0kZ6xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    directory=data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSrDjjkFZ-fW",
        "outputId": "f4669079-7f85-4f2b-844d-cb105e6c6762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 51952 images belonging to 20 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "   rescale=1.0 / 255,\n",
        "   rotation_range=30,\n",
        "   width_shift_range=0.2,\n",
        "   height_shift_range=0.2,\n",
        "   vertical_flip=True,\n",
        ")"
      ],
      "metadata": {
        "id": "Mgp7VGLnZ-dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory=data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=1,\n",
        "    class_mode=None,\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOP6e6CtZ-bE",
        "outputId": "e56cc77c-2574-4e83-9f98-8588981c1a01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 51952 images belonging to 20 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "            keras.Input(shape = (32, 32, 1)),\n",
        "            layers.Conv2D(32, 3, padding = 'same', activation = 'relu', name=\"Conv1\"),\n",
        "            layers.Conv2D(32, 3, padding = 'same', activation = 'relu', name=\"Conv2\"),\n",
        "            layers.Conv2D(32, 3, padding = 'same', activation = 'relu', name=\"Conv3\"),\n",
        "            layers.MaxPooling2D(name=\"Maxpool1\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv4\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv5\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv6\"),\n",
        "            layers.MaxPooling2D(name=\"Maxpool2\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv7\"),\n",
        "            layers.Conv2D(128, 3, padding = 'same', activation = 'relu', name=\"Conv8\"),\n",
        "            layers.Flatten(name=\"Flatten1\"),\n",
        "            layers.Dense(128, activation = 'relu', name=\"Dense1\"),\n",
        "            layers.Dense(20, activation = 'softmax', name=\"Dense2\"),\n",
        "])"
      ],
      "metadata": {
        "id": "xC5W6R-Wm1TP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adam =  keras.optimizers.Adam(lr = 1e-3)"
      ],
      "metadata": {
        "id": "2V05ebCknN01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "        loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "        optimizer = adam,\n",
        "        metrics = ['acc'],\n",
        ")"
      ],
      "metadata": {
        "id": "-4ZAIXSfnVNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', patience = 2, verbose = 1, factor = 0.5, min_lr = 1e-7)"
      ],
      "metadata": {
        "id": "p9pPVB31oyYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size"
      ],
      "metadata": {
        "id": "IfwxKkEinX1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = model.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    epochs=10\n",
        "                    callbacks=[reduce_lr]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iehx7HH9Z-Xj",
        "outputId": "eb3e0751-275c-4412-bc8b-1a0cd72bfadb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-f123216d65bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m classifier = model.fit_generator(generator=train_generator,\n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0;31m# steps_per_epoch=STEP_SIZE_TRAIN,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0;31m# validation_data=valid_generator,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0;31m# validation_steps=STEP_SIZE_VALID,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0;31m# epochs=10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2221\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2223\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2225\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n      handler_func(fileobj, events)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n      self._handle_recv()\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n      self._run_callback(callback, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n      callback(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n      return self.dispatch_shell(stream, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n      handler(stream, idents, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n      user_expressions, allow_stdin)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n      if self.run_code(code, result):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-21-429412f5a179>\", line 5, in <module>\n      epochs=10,\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 2223, in fit_generator\n      initial_epoch=initial_epoch)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 919, in compute_loss\n      y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1863, in sparse_categorical_crossentropy\n      y_true, y_pred, from_logits=from_logits, axis=axis)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5203, in sparse_categorical_crossentropy\n      labels=target, logits=output)\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [32,20] and labels shape [640]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_1311]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate_generator(generator=valid_generator,\n",
        "steps=STEP_SIZE_VALID)"
      ],
      "metadata": {
        "id": "wc94swvWZ-UB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_v5TAXFmZ-Qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hdAamlvDZ-Nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "b6KnbA9sYK4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00pV25MsvP1I"
      },
      "source": [
        "# Pytorch Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aW4pU14TULpi"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2qqtnBveIKU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5o5S2yLeIFa"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Resize([32,32]),\n",
        "    #  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "path = \"/content/gdrive/MyDrive/PreProcessDataset\"\n",
        "batch_size = 128\n",
        "\n",
        "trainset = torchvision.datasets.ImageFolder(path, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG4uwy70eICg"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.fc1 = nn.Linear(128 * 8 * 8, 128)\n",
        "        self.fc2 = nn.Linear(128, 20)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = torch.flatten(x, 1) \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.softmax(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "net.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWo1XwabeH_p"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsOkONcSeH8Z"
      },
      "outputs": [],
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 10 == 9:    \n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 10:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhjbEXNgMnMU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "c1fWmsuFZG65",
        "00pV25MsvP1I"
      ],
      "name": "Handwritten Amharic Digit Recognition Using Deep Learning.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}