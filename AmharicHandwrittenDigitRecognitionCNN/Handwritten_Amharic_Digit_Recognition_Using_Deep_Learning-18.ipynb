{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mukerem/AmharicHandwrittenDigitRecognitionCNN/blob/main/Handwritten_Amharic_Digit_Recognition_Using_Deep_Learning-18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29kuFJREaKYO",
        "outputId": "8834e6ac-6e72-433e-cd64-ac035ce47751"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceCPcifFah1-"
      },
      "source": [
        "# **Load library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmIQsuCTbSBd"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/gdrive/MyDrive/PreProcessV1.zip' -d \"/content/gdrive/MyDrive/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcKozwcMZzr6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "\n",
        "config = tf.compat.v1.ConfigProto( device_count = {'GPU': 1 , 'CPU': 56} ) \n",
        "sess = tf.compat.v1.Session(config=config) \n",
        "K.set_session(sess)\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaJv2RwyRfCN",
        "outputId": "1dbe5365-9f13-4195-e8a4-97a8317163cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/PreProcessV1\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive/PreProcessV1/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0pycJHOZS1n"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "img_height = 32\n",
        "img_width = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPzXdMv3cE5M"
      },
      "outputs": [],
      "source": [
        "data_dir = \"/content/gdrive/MyDrive/PreProcessV1/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV3b0cetmmDq"
      },
      "source": [
        "### **keras**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9pKCR0DcEtS",
        "outputId": "a0afde33-c3e2-4a9c-d3b0-8237f07984ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 51952 files belonging to 20 classes.\n",
            "Using 41562 files for training.\n"
          ]
        }
      ],
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  color_mode=\"grayscale\",\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53UWblhpdZ95",
        "outputId": "6521f15a-876e-4b34-febc-c539c71616f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 51952 files belonging to 20 classes.\n",
            "Using 10390 files for validation.\n"
          ]
        }
      ],
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  color_mode=\"grayscale\",\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzBg_kpbeIVB"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piJRCwqKm_vm"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "            keras.Input(shape = (32, 32, 1)),\n",
        "            layers.Conv2D(32, 3, padding = 'same', activation = 'relu', name=\"Conv1\"),\n",
        "            layers.Conv2D(32, 3, padding = 'same', activation = 'relu', name=\"Conv2\"),\n",
        "            layers.Conv2D(32, 3, padding = 'same', activation = 'relu', name=\"Conv3\"),\n",
        "            layers.MaxPooling2D(name=\"Maxpool1\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv4\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv5\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv6\"),\n",
        "            layers.MaxPooling2D(name=\"Maxpool2\"),\n",
        "            layers.Dropout(0.25, input_shape=(2,), name=\"Dropout1\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv7\"),\n",
        "            layers.MaxPooling2D(name=\"Maxpool3\"),\n",
        "            layers.Dropout(0.25, input_shape=(2,), name=\"Dropout2\"),\n",
        "            layers.Conv2D(128, 3, padding = 'same', activation = 'relu', name=\"Conv8\"),\n",
        "            layers.Flatten(name=\"Flatten1\"),\n",
        "            layers.Dropout(0.3, input_shape=(2,), name=\"Dropout3\"),\n",
        "            layers.Dense(128, activation = 'relu', name=\"Dense1\"),\n",
        "            layers.Dense(20, activation = 'softmax', name=\"Dense2\"),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APq2vCdU4kV8",
        "outputId": "a18a16e7-e906-4967-f942-35f0edb97c20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Conv1 (Conv2D)              (None, 32, 32, 32)        320       \n",
            "                                                                 \n",
            " Conv2 (Conv2D)              (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " Conv3 (Conv2D)              (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " Maxpool1 (MaxPooling2D)     (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " Conv4 (Conv2D)              (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " Conv5 (Conv2D)              (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " Conv6 (Conv2D)              (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " Maxpool2 (MaxPooling2D)     (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " Dropout1 (Dropout)          (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " Conv7 (Conv2D)              (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " Maxpool3 (MaxPooling2D)     (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " Dropout2 (Dropout)          (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " Conv8 (Conv2D)              (None, 4, 4, 128)         73856     \n",
            "                                                                 \n",
            " Flatten1 (Flatten)          (None, 2048)              0         \n",
            "                                                                 \n",
            " Dropout3 (Dropout)          (None, 2048)              0         \n",
            "                                                                 \n",
            " Dense1 (Dense)              (None, 128)               262272    \n",
            "                                                                 \n",
            " Dense2 (Dense)              (None, 20)                2580      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 486,804\n",
            "Trainable params: 486,804\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gc-YimqF4TBW"
      },
      "outputs": [],
      "source": [
        "# nadam = tf.keras.optimizers.Nadam(\n",
        "#     learning_rate=1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Nadam\"\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ho7RD9fBVGmX"
      },
      "outputs": [],
      "source": [
        "# adamax = tf.keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzwfU5NdVK0f"
      },
      "outputs": [],
      "source": [
        "# sgd = tf.keras.optimizers.SGD(\n",
        "#     learning_rate=0.01,\n",
        "#     momentum=0.0,\n",
        "#     nesterov=False,\n",
        "#     name='SGD',\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7vCTvZQ4XKY"
      },
      "outputs": [],
      "source": [
        "adam =  keras.optimizers.Adam(lr = 5e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNubZ416Sviu"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "        loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "        optimizer = adam,\n",
        "        metrics = ['acc'],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwlAQESPeIOd"
      },
      "outputs": [],
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', patience = 2, verbose = 1, factor = 0.5, min_lr = 1e-7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ssxru6PafEl",
        "outputId": "b713a7a3-72e6-4c42-d65b-706ebb2fa095"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ],
      "source": [
        "checkpoint = ModelCheckpoint(\"best_models_epoch_{epoch:02d}-{acc:.4f}.h5\", monitor='val_acc', verbose=1,\n",
        "    save_best_only=True, mode='auto', period=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ob_iP5OgeIMD",
        "outputId": "af676ef0-4c62-4442-c5b0-092e13be61b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.4256 - acc: 0.8864\n",
            "Epoch 1: val_acc improved from -inf to 0.91771, saving model to best_models_epoch_01-0.8865.h5\n",
            "1299/1299 [==============================] - 27s 21ms/step - loss: 0.4254 - acc: 0.8865 - val_loss: 0.3294 - val_acc: 0.9177 - lr: 5.0000e-04\n",
            "Epoch 2/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.3256 - acc: 0.9158\n",
            "Epoch 2: val_acc improved from 0.91771 to 0.91963, saving model to best_models_epoch_02-0.9158.h5\n",
            "1299/1299 [==============================] - 27s 20ms/step - loss: 0.3254 - acc: 0.9158 - val_loss: 0.3267 - val_acc: 0.9196 - lr: 5.0000e-04\n",
            "Epoch 3/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.2765 - acc: 0.9282\n",
            "Epoch 3: val_acc improved from 0.91963 to 0.93263, saving model to best_models_epoch_03-0.9282.h5\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.2763 - acc: 0.9282 - val_loss: 0.2768 - val_acc: 0.9326 - lr: 5.0000e-04\n",
            "Epoch 4/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.2354 - acc: 0.9395\n",
            "Epoch 4: val_acc improved from 0.93263 to 0.93571, saving model to best_models_epoch_04-0.9395.h5\n",
            "1299/1299 [==============================] - 27s 21ms/step - loss: 0.2353 - acc: 0.9395 - val_loss: 0.2698 - val_acc: 0.9357 - lr: 5.0000e-04\n",
            "Epoch 5/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.2103 - acc: 0.9459\n",
            "Epoch 5: val_acc improved from 0.93571 to 0.94235, saving model to best_models_epoch_05-0.9460.h5\n",
            "1299/1299 [==============================] - 27s 20ms/step - loss: 0.2102 - acc: 0.9460 - val_loss: 0.2545 - val_acc: 0.9423 - lr: 5.0000e-04\n",
            "Epoch 6/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.1917 - acc: 0.9497\n",
            "Epoch 6: val_acc improved from 0.94235 to 0.94302, saving model to best_models_epoch_06-0.9497.h5\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.1917 - acc: 0.9497 - val_loss: 0.2554 - val_acc: 0.9430 - lr: 5.0000e-04\n",
            "Epoch 7/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.1760 - acc: 0.9539\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 7: val_acc did not improve from 0.94302\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.1759 - acc: 0.9539 - val_loss: 0.2629 - val_acc: 0.9410 - lr: 5.0000e-04\n",
            "Epoch 8/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.1274 - acc: 0.9666\n",
            "Epoch 8: val_acc improved from 0.94302 to 0.95371, saving model to best_models_epoch_08-0.9666.h5\n",
            "1299/1299 [==============================] - 27s 21ms/step - loss: 0.1274 - acc: 0.9666 - val_loss: 0.2245 - val_acc: 0.9537 - lr: 2.5000e-04\n",
            "Epoch 9/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.1118 - acc: 0.9703\n",
            "Epoch 9: val_acc did not improve from 0.95371\n",
            "1299/1299 [==============================] - 27s 20ms/step - loss: 0.1118 - acc: 0.9703 - val_loss: 0.2160 - val_acc: 0.9518 - lr: 2.5000e-04\n",
            "Epoch 10/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.0997 - acc: 0.9735\n",
            "Epoch 10: val_acc improved from 0.95371 to 0.95486, saving model to best_models_epoch_10-0.9735.h5\n",
            "1299/1299 [==============================] - 27s 20ms/step - loss: 0.0997 - acc: 0.9735 - val_loss: 0.2247 - val_acc: 0.9549 - lr: 2.5000e-04\n",
            "Epoch 11/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.0928 - acc: 0.9752\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 11: val_acc did not improve from 0.95486\n",
            "1299/1299 [==============================] - 27s 20ms/step - loss: 0.0928 - acc: 0.9752 - val_loss: 0.2293 - val_acc: 0.9524 - lr: 2.5000e-04\n",
            "Epoch 12/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.0754 - acc: 0.9798\n",
            "Epoch 12: val_acc did not improve from 0.95486\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0754 - acc: 0.9799 - val_loss: 0.2296 - val_acc: 0.9543 - lr: 1.2500e-04\n",
            "Epoch 13/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.0637 - acc: 0.9816\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 13: val_acc did not improve from 0.95486\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0637 - acc: 0.9816 - val_loss: 0.2323 - val_acc: 0.9548 - lr: 1.2500e-04\n",
            "Epoch 14/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.0553 - acc: 0.9836\n",
            "Epoch 14: val_acc improved from 0.95486 to 0.95525, saving model to best_models_epoch_14-0.9836.h5\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0553 - acc: 0.9836 - val_loss: 0.2270 - val_acc: 0.9552 - lr: 6.2500e-05\n",
            "Epoch 15/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.0489 - acc: 0.9862\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\n",
            "Epoch 15: val_acc did not improve from 0.95525\n",
            "1299/1299 [==============================] - 27s 20ms/step - loss: 0.0489 - acc: 0.9862 - val_loss: 0.2392 - val_acc: 0.9552 - lr: 6.2500e-05\n",
            "Epoch 16/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.0446 - acc: 0.9870\n",
            "Epoch 16: val_acc improved from 0.95525 to 0.95659, saving model to best_models_epoch_16-0.9870.h5\n",
            "1299/1299 [==============================] - 27s 20ms/step - loss: 0.0446 - acc: 0.9870 - val_loss: 0.2405 - val_acc: 0.9566 - lr: 3.1250e-05\n",
            "Epoch 17/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.0407 - acc: 0.9884\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\n",
            "Epoch 17: val_acc did not improve from 0.95659\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0407 - acc: 0.9884 - val_loss: 0.2482 - val_acc: 0.9557 - lr: 3.1250e-05\n",
            "Epoch 18/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9886\n",
            "Epoch 18: val_acc did not improve from 0.95659\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0393 - acc: 0.9885 - val_loss: 0.2487 - val_acc: 0.9566 - lr: 1.5625e-05\n",
            "Epoch 19/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9881\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\n",
            "Epoch 19: val_acc improved from 0.95659 to 0.95698, saving model to best_models_epoch_19-0.9881.h5\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0384 - acc: 0.9881 - val_loss: 0.2481 - val_acc: 0.9570 - lr: 1.5625e-05\n",
            "Epoch 20/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.0366 - acc: 0.9891\n",
            "Epoch 20: val_acc improved from 0.95698 to 0.95746, saving model to best_models_epoch_20-0.9891.h5\n",
            "1299/1299 [==============================] - 27s 21ms/step - loss: 0.0366 - acc: 0.9891 - val_loss: 0.2514 - val_acc: 0.9575 - lr: 7.8125e-06\n",
            "Epoch 21/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9896\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "\n",
            "Epoch 21: val_acc improved from 0.95746 to 0.95756, saving model to best_models_epoch_21-0.9896.h5\n",
            "1299/1299 [==============================] - 27s 21ms/step - loss: 0.0357 - acc: 0.9896 - val_loss: 0.2509 - val_acc: 0.9576 - lr: 7.8125e-06\n",
            "Epoch 22/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.0356 - acc: 0.9895\n",
            "Epoch 22: val_acc improved from 0.95756 to 0.95765, saving model to best_models_epoch_22-0.9895.h5\n",
            "1299/1299 [==============================] - 27s 20ms/step - loss: 0.0356 - acc: 0.9895 - val_loss: 0.2525 - val_acc: 0.9577 - lr: 3.9063e-06\n",
            "Epoch 23/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9896\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
            "\n",
            "Epoch 23: val_acc did not improve from 0.95765\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0353 - acc: 0.9896 - val_loss: 0.2533 - val_acc: 0.9572 - lr: 3.9063e-06\n",
            "Epoch 24/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.0338 - acc: 0.9903\n",
            "Epoch 24: val_acc did not improve from 0.95765\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0338 - acc: 0.9903 - val_loss: 0.2540 - val_acc: 0.9573 - lr: 1.9531e-06\n",
            "Epoch 25/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9897\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
            "\n",
            "Epoch 25: val_acc did not improve from 0.95765\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0341 - acc: 0.9898 - val_loss: 0.2546 - val_acc: 0.9573 - lr: 1.9531e-06\n",
            "Epoch 26/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9898\n",
            "Epoch 26: val_acc did not improve from 0.95765\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0343 - acc: 0.9898 - val_loss: 0.2548 - val_acc: 0.9574 - lr: 9.7656e-07\n",
            "Epoch 27/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9899\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
            "\n",
            "Epoch 27: val_acc did not improve from 0.95765\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0342 - acc: 0.9899 - val_loss: 0.2549 - val_acc: 0.9574 - lr: 9.7656e-07\n",
            "Epoch 28/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9895\n",
            "Epoch 28: val_acc did not improve from 0.95765\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0341 - acc: 0.9895 - val_loss: 0.2551 - val_acc: 0.9574 - lr: 4.8828e-07\n",
            "Epoch 29/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9896\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
            "\n",
            "Epoch 29: val_acc did not improve from 0.95765\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0348 - acc: 0.9896 - val_loss: 0.2551 - val_acc: 0.9574 - lr: 4.8828e-07\n",
            "Epoch 30/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.0354 - acc: 0.9891\n",
            "Epoch 30: val_acc did not improve from 0.95765\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0354 - acc: 0.9891 - val_loss: 0.2551 - val_acc: 0.9574 - lr: 2.4414e-07\n"
          ]
        }
      ],
      "source": [
        "classifier = model.fit(train_ds, batch_size = batch_size, \n",
        "                                 epochs = 30,\n",
        "                                 callbacks=[reduce_lr, checkpoint],\n",
        "                                 validation_data = val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghprZPhjGt4K"
      },
      "outputs": [],
      "source": [
        "# model.save('/content/gdrive/MyDrive/30-epoch-val-acc-9600-lr-5e-4-two-dropout-2e-1-batch-32-adam.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1fWmsuFZG65"
      },
      "source": [
        "### **Data Augmentation**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XERb7b_DO3jE"
      },
      "outputs": [],
      "source": [
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "   rescale=1.0 / 255,\n",
        "   rotation_range=30,\n",
        "   width_shift_range=0.2,\n",
        "   height_shift_range=0.2,\n",
        "   vertical_flip=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EavxErWdZxYL",
        "outputId": "ffd6a80a-f1f9-46e3-b7cc-228ea6efb62d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 51952 images belonging to 20 classes.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjIuEERLdM2a",
        "outputId": "a443ce00-246c-4668-807e-6f100051515a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.preprocessing.image.DirectoryIterator at 0x7f843b0df910>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nqk5FL0kZ6xu"
      },
      "outputs": [],
      "source": [
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "   rescale=1.0 / 255,\n",
        "   rotation_range=30,\n",
        "   width_shift_range=0.2,\n",
        "   height_shift_range=0.2,\n",
        "   vertical_flip=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSrDjjkFZ-fW",
        "outputId": "f4669079-7f85-4f2b-844d-cb105e6c6762"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 51952 images belonging to 20 classes.\n"
          ]
        }
      ],
      "source": [
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    directory=data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mgp7VGLnZ-dt"
      },
      "outputs": [],
      "source": [
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "   rescale=1.0 / 255,\n",
        "   rotation_range=30,\n",
        "   width_shift_range=0.2,\n",
        "   height_shift_range=0.2,\n",
        "   vertical_flip=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOP6e6CtZ-bE",
        "outputId": "e56cc77c-2574-4e83-9f98-8588981c1a01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 51952 images belonging to 20 classes.\n"
          ]
        }
      ],
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory=data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=1,\n",
        "    class_mode=None,\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xC5W6R-Wm1TP"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "            keras.Input(shape = (32, 32, 1)),\n",
        "            layers.Conv2D(32, 3, padding = 'same', activation = 'relu', name=\"Conv1\"),\n",
        "            layers.Conv2D(32, 3, padding = 'same', activation = 'relu', name=\"Conv2\"),\n",
        "            layers.Conv2D(32, 3, padding = 'same', activation = 'relu', name=\"Conv3\"),\n",
        "            layers.MaxPooling2D(name=\"Maxpool1\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv4\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv5\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv6\"),\n",
        "            layers.MaxPooling2D(name=\"Maxpool2\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv7\"),\n",
        "            layers.Conv2D(128, 3, padding = 'same', activation = 'relu', name=\"Conv8\"),\n",
        "            layers.Flatten(name=\"Flatten1\"),\n",
        "            layers.Dense(128, activation = 'relu', name=\"Dense1\"),\n",
        "            layers.Dense(20, activation = 'softmax', name=\"Dense2\"),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2V05ebCknN01"
      },
      "outputs": [],
      "source": [
        "adam =  keras.optimizers.Adam(lr = 1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4ZAIXSfnVNd"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "        loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "        optimizer = adam,\n",
        "        metrics = ['acc'],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9pPVB31oyYb"
      },
      "outputs": [],
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', patience = 2, verbose = 1, factor = 0.5, min_lr = 1e-7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfwxKkEinX1L"
      },
      "outputs": [],
      "source": [
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iehx7HH9Z-Xj",
        "outputId": "eb3e0751-275c-4412-bc8b-1a0cd72bfadb"
      },
      "outputs": [
        {
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-f123216d65bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m classifier = model.fit_generator(generator=train_generator,\n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0;31m# steps_per_epoch=STEP_SIZE_TRAIN,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0;31m# validation_data=valid_generator,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0;31m# validation_steps=STEP_SIZE_VALID,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0;31m# epochs=10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2221\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2223\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2225\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n      handler_func(fileobj, events)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n      self._handle_recv()\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n      self._run_callback(callback, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n      callback(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n      return self.dispatch_shell(stream, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n      handler(stream, idents, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n      user_expressions, allow_stdin)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n      if self.run_code(code, result):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-21-429412f5a179>\", line 5, in <module>\n      epochs=10,\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 2223, in fit_generator\n      initial_epoch=initial_epoch)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 919, in compute_loss\n      y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1863, in sparse_categorical_crossentropy\n      y_true, y_pred, from_logits=from_logits, axis=axis)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5203, in sparse_categorical_crossentropy\n      labels=target, logits=output)\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [32,20] and labels shape [640]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_1311]"
          ]
        }
      ],
      "source": [
        "classifier = model.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    epochs=10\n",
        "                    callbacks=[reduce_lr]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wc94swvWZ-UB"
      },
      "outputs": [],
      "source": [
        "model.evaluate_generator(generator=valid_generator,\n",
        "steps=STEP_SIZE_VALID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_v5TAXFmZ-Qw"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdAamlvDZ-Nl"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6KnbA9sYK4T"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00pV25MsvP1I"
      },
      "source": [
        "# Pytorch Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aW4pU14TULpi"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2qqtnBveIKU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5o5S2yLeIFa"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Resize([32,32]),\n",
        "    #  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "path = \"/content/gdrive/MyDrive/PreProcessDataset\"\n",
        "batch_size = 128\n",
        "\n",
        "trainset = torchvision.datasets.ImageFolder(path, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG4uwy70eICg"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.fc1 = nn.Linear(128 * 8 * 8, 128)\n",
        "        self.fc2 = nn.Linear(128, 20)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = torch.flatten(x, 1) \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.softmax(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "net.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWo1XwabeH_p"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsOkONcSeH8Z"
      },
      "outputs": [],
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 10 == 9:    \n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 10:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhjbEXNgMnMU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "c1fWmsuFZG65",
        "00pV25MsvP1I"
      ],
      "name": "Handwritten Amharic Digit Recognition Using Deep Learning.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}