{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mukerem/AmharicHandwrittenDigitRecognitionCNN/blob/main/Handwritten_Amharic_Digit_Recognition_Using_Deep_Learning-18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "29kuFJREaKYO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8834e6ac-6e72-433e-cd64-ac035ce47751"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceCPcifFah1-"
      },
      "source": [
        "# **Load library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmIQsuCTbSBd"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/gdrive/MyDrive/PreProcessV1.zip' -d \"/content/gdrive/MyDrive/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "UcKozwcMZzr6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "\n",
        "config = tf.compat.v1.ConfigProto( device_count = {'GPU': 1 , 'CPU': 56} ) \n",
        "sess = tf.compat.v1.Session(config=config) \n",
        "K.set_session(sess)\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaJv2RwyRfCN",
        "outputId": "1dbe5365-9f13-4195-e8a4-97a8317163cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/PreProcessV1\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive/PreProcessV1/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "i0pycJHOZS1n"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "img_height = 32\n",
        "img_width = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "QPzXdMv3cE5M"
      },
      "outputs": [],
      "source": [
        "data_dir = \"/content/gdrive/MyDrive/PreProcessV1/\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **keras**\n"
      ],
      "metadata": {
        "id": "sV3b0cetmmDq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9pKCR0DcEtS",
        "outputId": "a0afde33-c3e2-4a9c-d3b0-8237f07984ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 51952 files belonging to 20 classes.\n",
            "Using 41562 files for training.\n"
          ]
        }
      ],
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  color_mode=\"grayscale\",\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53UWblhpdZ95",
        "outputId": "6521f15a-876e-4b34-febc-c539c71616f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 51952 files belonging to 20 classes.\n",
            "Using 10390 files for validation.\n"
          ]
        }
      ],
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  color_mode=\"grayscale\",\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "CzBg_kpbeIVB"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "            keras.Input(shape = (32, 32, 1)),\n",
        "            layers.Conv2D(32, 3, padding = 'same', activation = 'relu', name=\"Conv1\"),\n",
        "            layers.Conv2D(32, 3, padding = 'same', activation = 'relu', name=\"Conv2\"),\n",
        "            layers.Conv2D(32, 3, padding = 'same', activation = 'relu', name=\"Conv3\"),\n",
        "            layers.MaxPooling2D(name=\"Maxpool1\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv4\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv5\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv6\"),\n",
        "            layers.MaxPooling2D(name=\"Maxpool2\"),\n",
        "            layers.Dropout(0.25, input_shape=(2,), name=\"Dropout1\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv7\"),\n",
        "            layers.MaxPooling2D(name=\"Maxpool3\"),\n",
        "            layers.Dropout(0.3, input_shape=(2,), name=\"Dropout2\"),\n",
        "            layers.Conv2D(128, 3, padding = 'same', activation = 'relu', name=\"Conv8\"),\n",
        "            layers.Flatten(name=\"Flatten1\"),\n",
        "            layers.Dense(256, activation = 'relu', name=\"Dense1\"),\n",
        "            layers.Dense(64, activation = 'relu', name=\"Dense2\"),\n",
        "            layers.Dense(20, activation = 'softmax', name=\"Dense3\"),\n",
        "])"
      ],
      "metadata": {
        "id": "piJRCwqKm_vm"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APq2vCdU4kV8",
        "outputId": "d8dc6fd1-8fce-4d14-8e9e-0d86bfa3a925"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Conv1 (Conv2D)              (None, 32, 32, 32)        320       \n",
            "                                                                 \n",
            " Conv2 (Conv2D)              (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " Conv3 (Conv2D)              (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " Maxpool1 (MaxPooling2D)     (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " Conv4 (Conv2D)              (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " Conv5 (Conv2D)              (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " Conv6 (Conv2D)              (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " Maxpool2 (MaxPooling2D)     (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " Dropout1 (Dropout)          (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " Conv7 (Conv2D)              (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " Maxpool3 (MaxPooling2D)     (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " Dropout2 (Dropout)          (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " Conv8 (Conv2D)              (None, 4, 4, 128)         73856     \n",
            "                                                                 \n",
            " Flatten1 (Flatten)          (None, 2048)              0         \n",
            "                                                                 \n",
            " Dense1 (Dense)              (None, 256)               524544    \n",
            "                                                                 \n",
            " Dense2 (Dense)              (None, 64)                16448     \n",
            "                                                                 \n",
            " Dense3 (Dense)              (None, 20)                1300      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 764,244\n",
            "Trainable params: 764,244\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nadam = tf.keras.optimizers.Nadam(\n",
        "#     learning_rate=1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Nadam\"\n",
        "# )"
      ],
      "metadata": {
        "id": "Gc-YimqF4TBW"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adamax = tf.keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)"
      ],
      "metadata": {
        "id": "ho7RD9fBVGmX"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sgd = tf.keras.optimizers.SGD(\n",
        "#     learning_rate=0.01,\n",
        "#     momentum=0.0,\n",
        "#     nesterov=False,\n",
        "#     name='SGD',\n",
        "# )"
      ],
      "metadata": {
        "id": "QzwfU5NdVK0f"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adam =  keras.optimizers.Adam(lr = 1e-3)"
      ],
      "metadata": {
        "id": "Q7vCTvZQ4XKY"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "        loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "        optimizer = adam,\n",
        "        metrics = ['acc'],\n",
        ")"
      ],
      "metadata": {
        "id": "PNubZ416Sviu"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "MwlAQESPeIOd"
      },
      "outputs": [],
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', patience = 2, verbose = 1, factor = 0.5, min_lr = 1e-7)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(\"best_model_epoch_{epoch:02d}-{100*val_acc:.2f}.h5\", monitor='val_acc', verbose=1,\n",
        "    save_best_only=True, mode='auto', save_freq=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ssxru6PafEl",
        "outputId": "12b97799-238b-4e96-ae8a-7f270cb52b50"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ob_iP5OgeIMD",
        "outputId": "d0cb2973-6f89-475c-9d06-c04d2c023723"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 1.3663 - acc: 0.5802\n",
            "Epoch 1: val_acc improved from -inf to 0.84793, saving model to best_model_epoch_01-0.58.h5\n",
            "1299/1299 [==============================] - 28s 21ms/step - loss: 1.3663 - acc: 0.5802 - val_loss: 0.5772 - val_acc: 0.8479 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.4580 - acc: 0.8772\n",
            "Epoch 2: val_acc improved from 0.84793 to 0.91049, saving model to best_model_epoch_02-0.35.h5\n",
            "1299/1299 [==============================] - 28s 21ms/step - loss: 0.4578 - acc: 0.8773 - val_loss: 0.3497 - val_acc: 0.9105 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.3474 - acc: 0.9104\n",
            "Epoch 3: val_acc improved from 0.91049 to 0.92647, saving model to best_model_epoch_03-0.29.h5\n",
            "1299/1299 [==============================] - 27s 21ms/step - loss: 0.3474 - acc: 0.9104 - val_loss: 0.2936 - val_acc: 0.9265 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.2982 - acc: 0.9225\n",
            "Epoch 4: val_acc improved from 0.92647 to 0.92656, saving model to best_model_epoch_04-0.31.h5\n",
            "1299/1299 [==============================] - 27s 20ms/step - loss: 0.2982 - acc: 0.9225 - val_loss: 0.3088 - val_acc: 0.9266 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.2699 - acc: 0.9317\n",
            "Epoch 5: val_acc improved from 0.92656 to 0.93484, saving model to best_model_epoch_05-0.27.h5\n",
            "1299/1299 [==============================] - 27s 21ms/step - loss: 0.2698 - acc: 0.9318 - val_loss: 0.2717 - val_acc: 0.9348 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.2443 - acc: 0.9367\n",
            "Epoch 6: val_acc improved from 0.93484 to 0.93782, saving model to best_model_epoch_06-0.27.h5\n",
            "1299/1299 [==============================] - 27s 21ms/step - loss: 0.2441 - acc: 0.9368 - val_loss: 0.2718 - val_acc: 0.9378 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.2409 - acc: 0.9386\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 7: val_acc did not improve from 0.93782\n",
            "1299/1299 [==============================] - 27s 20ms/step - loss: 0.2410 - acc: 0.9386 - val_loss: 0.2765 - val_acc: 0.9344 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.1605 - acc: 0.9592\n",
            "Epoch 8: val_acc improved from 0.93782 to 0.94524, saving model to best_model_epoch_08-0.24.h5\n",
            "1299/1299 [==============================] - 27s 21ms/step - loss: 0.1605 - acc: 0.9591 - val_loss: 0.2441 - val_acc: 0.9452 - lr: 5.0000e-04\n",
            "Epoch 9/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.1372 - acc: 0.9645\n",
            "Epoch 9: val_acc improved from 0.94524 to 0.95053, saving model to best_model_epoch_09-0.23.h5\n",
            "1299/1299 [==============================] - 27s 21ms/step - loss: 0.1373 - acc: 0.9645 - val_loss: 0.2303 - val_acc: 0.9505 - lr: 5.0000e-04\n",
            "Epoch 10/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.1245 - acc: 0.9670\n",
            "Epoch 10: val_acc improved from 0.95053 to 0.95111, saving model to best_model_epoch_10-0.23.h5\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.1245 - acc: 0.9670 - val_loss: 0.2282 - val_acc: 0.9511 - lr: 5.0000e-04\n",
            "Epoch 11/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.1184 - acc: 0.9676\n",
            "Epoch 11: val_acc did not improve from 0.95111\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.1184 - acc: 0.9676 - val_loss: 0.2404 - val_acc: 0.9485 - lr: 5.0000e-04\n",
            "Epoch 12/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.1143 - acc: 0.9699\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 12: val_acc did not improve from 0.95111\n",
            "1299/1299 [==============================] - 27s 21ms/step - loss: 0.1143 - acc: 0.9699 - val_loss: 0.2547 - val_acc: 0.9468 - lr: 5.0000e-04\n",
            "Epoch 13/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.0832 - acc: 0.9768\n",
            "Epoch 13: val_acc improved from 0.95111 to 0.95178, saving model to best_model_epoch_13-0.24.h5\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0832 - acc: 0.9768 - val_loss: 0.2444 - val_acc: 0.9518 - lr: 2.5000e-04\n",
            "Epoch 14/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.0703 - acc: 0.9805\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 14: val_acc improved from 0.95178 to 0.95303, saving model to best_model_epoch_14-0.25.h5\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0703 - acc: 0.9805 - val_loss: 0.2468 - val_acc: 0.9530 - lr: 2.5000e-04\n",
            "Epoch 15/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.0543 - acc: 0.9848\n",
            "Epoch 15: val_acc improved from 0.95303 to 0.95467, saving model to best_model_epoch_15-0.25.h5\n",
            "1299/1299 [==============================] - 27s 21ms/step - loss: 0.0543 - acc: 0.9848 - val_loss: 0.2503 - val_acc: 0.9547 - lr: 1.2500e-04\n",
            "Epoch 16/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.0504 - acc: 0.9850\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 16: val_acc did not improve from 0.95467\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0504 - acc: 0.9850 - val_loss: 0.2618 - val_acc: 0.9533 - lr: 1.2500e-04\n",
            "Epoch 17/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.0416 - acc: 0.9874\n",
            "Epoch 17: val_acc improved from 0.95467 to 0.95582, saving model to best_model_epoch_17-0.26.h5\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0416 - acc: 0.9874 - val_loss: 0.2613 - val_acc: 0.9558 - lr: 6.2500e-05\n",
            "Epoch 18/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9884\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\n",
            "Epoch 18: val_acc did not improve from 0.95582\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0395 - acc: 0.9884 - val_loss: 0.2674 - val_acc: 0.9548 - lr: 6.2500e-05\n",
            "Epoch 19/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.0361 - acc: 0.9891\n",
            "Epoch 19: val_acc did not improve from 0.95582\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0361 - acc: 0.9891 - val_loss: 0.2716 - val_acc: 0.9551 - lr: 3.1250e-05\n",
            "Epoch 20/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9895\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\n",
            "Epoch 20: val_acc did not improve from 0.95582\n",
            "1299/1299 [==============================] - 27s 21ms/step - loss: 0.0345 - acc: 0.9895 - val_loss: 0.2759 - val_acc: 0.9552 - lr: 3.1250e-05\n",
            "Epoch 21/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9895\n",
            "Epoch 21: val_acc did not improve from 0.95582\n",
            "1299/1299 [==============================] - 27s 21ms/step - loss: 0.0330 - acc: 0.9895 - val_loss: 0.2785 - val_acc: 0.9552 - lr: 1.5625e-05\n",
            "Epoch 22/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9900\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\n",
            "Epoch 22: val_acc did not improve from 0.95582\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0321 - acc: 0.9900 - val_loss: 0.2768 - val_acc: 0.9550 - lr: 1.5625e-05\n",
            "Epoch 23/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9906\n",
            "Epoch 23: val_acc did not improve from 0.95582\n",
            "1299/1299 [==============================] - 27s 20ms/step - loss: 0.0305 - acc: 0.9906 - val_loss: 0.2780 - val_acc: 0.9550 - lr: 7.8125e-06\n",
            "Epoch 24/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.0295 - acc: 0.9910\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "\n",
            "Epoch 24: val_acc did not improve from 0.95582\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0295 - acc: 0.9910 - val_loss: 0.2806 - val_acc: 0.9550 - lr: 7.8125e-06\n",
            "Epoch 25/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9901\n",
            "Epoch 25: val_acc did not improve from 0.95582\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0307 - acc: 0.9901 - val_loss: 0.2805 - val_acc: 0.9551 - lr: 3.9063e-06\n",
            "Epoch 26/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.0301 - acc: 0.9904\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
            "\n",
            "Epoch 26: val_acc did not improve from 0.95582\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0301 - acc: 0.9904 - val_loss: 0.2815 - val_acc: 0.9554 - lr: 3.9063e-06\n",
            "Epoch 27/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9909\n",
            "Epoch 27: val_acc did not improve from 0.95582\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0285 - acc: 0.9910 - val_loss: 0.2817 - val_acc: 0.9551 - lr: 1.9531e-06\n",
            "Epoch 28/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.0284 - acc: 0.9909\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
            "\n",
            "Epoch 28: val_acc did not improve from 0.95582\n",
            "1299/1299 [==============================] - 27s 20ms/step - loss: 0.0284 - acc: 0.9909 - val_loss: 0.2819 - val_acc: 0.9551 - lr: 1.9531e-06\n",
            "Epoch 29/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.0285 - acc: 0.9908\n",
            "Epoch 29: val_acc did not improve from 0.95582\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0285 - acc: 0.9908 - val_loss: 0.2819 - val_acc: 0.9552 - lr: 9.7656e-07\n",
            "Epoch 30/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.0279 - acc: 0.9911\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
            "\n",
            "Epoch 30: val_acc did not improve from 0.95582\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0279 - acc: 0.9911 - val_loss: 0.2821 - val_acc: 0.9551 - lr: 9.7656e-07\n"
          ]
        }
      ],
      "source": [
        "classifier = model.fit(train_ds, batch_size = batch_size, \n",
        "                                 epochs = 30,\n",
        "                                 callbacks=[reduce_lr, checkpoint],\n",
        "                                 validation_data = val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ghprZPhjGt4K"
      },
      "outputs": [],
      "source": [
        "# model.save('/content/gdrive/MyDrive/30-epoch-val-acc-9589-lr-1e-3-two-dropout-2e-1-batch-32-adam.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data Augmentation**\n"
      ],
      "metadata": {
        "id": "c1fWmsuFZG65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "   rescale=1.0 / 255,\n",
        "   rotation_range=30,\n",
        "   width_shift_range=0.2,\n",
        "   height_shift_range=0.2,\n",
        "   vertical_flip=True,\n",
        ")"
      ],
      "metadata": {
        "id": "XERb7b_DO3jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EavxErWdZxYL",
        "outputId": "ffd6a80a-f1f9-46e3-b7cc-228ea6efb62d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 51952 images belonging to 20 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjIuEERLdM2a",
        "outputId": "a443ce00-246c-4668-807e-6f100051515a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.preprocessing.image.DirectoryIterator at 0x7f843b0df910>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "   rescale=1.0 / 255,\n",
        "   rotation_range=30,\n",
        "   width_shift_range=0.2,\n",
        "   height_shift_range=0.2,\n",
        "   vertical_flip=True,\n",
        ")"
      ],
      "metadata": {
        "id": "Nqk5FL0kZ6xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    directory=data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSrDjjkFZ-fW",
        "outputId": "f4669079-7f85-4f2b-844d-cb105e6c6762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 51952 images belonging to 20 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "   rescale=1.0 / 255,\n",
        "   rotation_range=30,\n",
        "   width_shift_range=0.2,\n",
        "   height_shift_range=0.2,\n",
        "   vertical_flip=True,\n",
        ")"
      ],
      "metadata": {
        "id": "Mgp7VGLnZ-dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory=data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=1,\n",
        "    class_mode=None,\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOP6e6CtZ-bE",
        "outputId": "e56cc77c-2574-4e83-9f98-8588981c1a01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 51952 images belonging to 20 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "            keras.Input(shape = (32, 32, 1)),\n",
        "            layers.Conv2D(32, 3, padding = 'same', activation = 'relu', name=\"Conv1\"),\n",
        "            layers.Conv2D(32, 3, padding = 'same', activation = 'relu', name=\"Conv2\"),\n",
        "            layers.Conv2D(32, 3, padding = 'same', activation = 'relu', name=\"Conv3\"),\n",
        "            layers.MaxPooling2D(name=\"Maxpool1\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv4\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv5\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv6\"),\n",
        "            layers.MaxPooling2D(name=\"Maxpool2\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv7\"),\n",
        "            layers.Conv2D(128, 3, padding = 'same', activation = 'relu', name=\"Conv8\"),\n",
        "            layers.Flatten(name=\"Flatten1\"),\n",
        "            layers.Dense(128, activation = 'relu', name=\"Dense1\"),\n",
        "            layers.Dense(20, activation = 'softmax', name=\"Dense2\"),\n",
        "])"
      ],
      "metadata": {
        "id": "xC5W6R-Wm1TP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adam =  keras.optimizers.Adam(lr = 1e-3)"
      ],
      "metadata": {
        "id": "2V05ebCknN01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "        loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "        optimizer = adam,\n",
        "        metrics = ['acc'],\n",
        ")"
      ],
      "metadata": {
        "id": "-4ZAIXSfnVNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', patience = 2, verbose = 1, factor = 0.5, min_lr = 1e-7)"
      ],
      "metadata": {
        "id": "p9pPVB31oyYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size"
      ],
      "metadata": {
        "id": "IfwxKkEinX1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = model.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    epochs=10\n",
        "                    callbacks=[reduce_lr]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iehx7HH9Z-Xj",
        "outputId": "eb3e0751-275c-4412-bc8b-1a0cd72bfadb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-f123216d65bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m classifier = model.fit_generator(generator=train_generator,\n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0;31m# steps_per_epoch=STEP_SIZE_TRAIN,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0;31m# validation_data=valid_generator,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0;31m# validation_steps=STEP_SIZE_VALID,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0;31m# epochs=10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2221\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2223\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2225\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n      handler_func(fileobj, events)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n      self._handle_recv()\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n      self._run_callback(callback, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n      callback(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n      return self.dispatch_shell(stream, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n      handler(stream, idents, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n      user_expressions, allow_stdin)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n      if self.run_code(code, result):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-21-429412f5a179>\", line 5, in <module>\n      epochs=10,\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 2223, in fit_generator\n      initial_epoch=initial_epoch)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 919, in compute_loss\n      y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1863, in sparse_categorical_crossentropy\n      y_true, y_pred, from_logits=from_logits, axis=axis)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5203, in sparse_categorical_crossentropy\n      labels=target, logits=output)\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [32,20] and labels shape [640]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_1311]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate_generator(generator=valid_generator,\n",
        "steps=STEP_SIZE_VALID)"
      ],
      "metadata": {
        "id": "wc94swvWZ-UB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_v5TAXFmZ-Qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hdAamlvDZ-Nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "b6KnbA9sYK4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00pV25MsvP1I"
      },
      "source": [
        "# Pytorch Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aW4pU14TULpi"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2qqtnBveIKU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5o5S2yLeIFa"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Resize([32,32]),\n",
        "    #  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "path = \"/content/gdrive/MyDrive/PreProcessDataset\"\n",
        "batch_size = 128\n",
        "\n",
        "trainset = torchvision.datasets.ImageFolder(path, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG4uwy70eICg"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.fc1 = nn.Linear(128 * 8 * 8, 128)\n",
        "        self.fc2 = nn.Linear(128, 20)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = torch.flatten(x, 1) \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.softmax(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "net.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWo1XwabeH_p"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsOkONcSeH8Z"
      },
      "outputs": [],
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 10 == 9:    \n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 10:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhjbEXNgMnMU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "c1fWmsuFZG65",
        "00pV25MsvP1I"
      ],
      "name": "Handwritten Amharic Digit Recognition Using Deep Learning.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}