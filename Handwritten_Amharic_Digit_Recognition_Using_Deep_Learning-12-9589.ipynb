{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mukerem/ACPC2020/blob/main/Handwritten_Amharic_Digit_Recognition_Using_Deep_Learning-12-9589.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "29kuFJREaKYO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8834e6ac-6e72-433e-cd64-ac035ce47751"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceCPcifFah1-"
      },
      "source": [
        "# **Load library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmIQsuCTbSBd"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/gdrive/MyDrive/PreProcessV1.zip' -d \"/content/gdrive/MyDrive/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "UcKozwcMZzr6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "\n",
        "config = tf.compat.v1.ConfigProto( device_count = {'GPU': 1 , 'CPU': 56} ) \n",
        "sess = tf.compat.v1.Session(config=config) \n",
        "K.set_session(sess)\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaJv2RwyRfCN",
        "outputId": "1dbe5365-9f13-4195-e8a4-97a8317163cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/PreProcessV1\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive/PreProcessV1/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "i0pycJHOZS1n"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "img_height = 32\n",
        "img_width = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "QPzXdMv3cE5M"
      },
      "outputs": [],
      "source": [
        "data_dir = \"/content/gdrive/MyDrive/PreProcessV1/\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **keras**\n"
      ],
      "metadata": {
        "id": "sV3b0cetmmDq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9pKCR0DcEtS",
        "outputId": "a0afde33-c3e2-4a9c-d3b0-8237f07984ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 51952 files belonging to 20 classes.\n",
            "Using 41562 files for training.\n"
          ]
        }
      ],
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  color_mode=\"grayscale\",\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53UWblhpdZ95",
        "outputId": "6521f15a-876e-4b34-febc-c539c71616f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 51952 files belonging to 20 classes.\n",
            "Using 10390 files for validation.\n"
          ]
        }
      ],
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  color_mode=\"grayscale\",\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "CzBg_kpbeIVB"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "            keras.Input(shape = (32, 32, 1)),\n",
        "            layers.Conv2D(32, 3, padding = 'same', activation = 'relu', name=\"Conv1\"),\n",
        "            layers.Conv2D(32, 3, padding = 'same', activation = 'relu', name=\"Conv2\"),\n",
        "            layers.Conv2D(32, 3, padding = 'same', activation = 'relu', name=\"Conv3\"),\n",
        "            layers.MaxPooling2D(name=\"Maxpool1\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv4\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv5\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv6\"),\n",
        "            layers.MaxPooling2D(name=\"Maxpool2\"),\n",
        "            layers.Dropout(0.25, input_shape=(2,)),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv7\"),\n",
        "            layers.MaxPooling2D(name=\"Maxpool3\"),\n",
        "            layers.Dropout(0.25, input_shape=(2,)),\n",
        "            layers.Conv2D(128, 3, padding = 'same', activation = 'relu', name=\"Conv8\"),\n",
        "            layers.Flatten(name=\"Flatten1\"),\n",
        "            layers.Dense(128, activation = 'relu', name=\"Dense1\"),\n",
        "            layers.Dense(20, activation = 'softmax', name=\"Dense2\"),\n",
        "])"
      ],
      "metadata": {
        "id": "piJRCwqKm_vm"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APq2vCdU4kV8",
        "outputId": "332f759e-1106-4b88-f418-8c36de2c627d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Conv1 (Conv2D)              (None, 32, 32, 32)        320       \n",
            "                                                                 \n",
            " Conv2 (Conv2D)              (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " Conv3 (Conv2D)              (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " Maxpool1 (MaxPooling2D)     (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " Conv4 (Conv2D)              (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " Conv5 (Conv2D)              (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " Conv6 (Conv2D)              (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " Maxpool2 (MaxPooling2D)     (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " Conv7 (Conv2D)              (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " Maxpool3 (MaxPooling2D)     (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " Conv8 (Conv2D)              (None, 4, 4, 128)         73856     \n",
            "                                                                 \n",
            " Flatten1 (Flatten)          (None, 2048)              0         \n",
            "                                                                 \n",
            " Dense1 (Dense)              (None, 128)               262272    \n",
            "                                                                 \n",
            " Dense2 (Dense)              (None, 20)                2580      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 486,804\n",
            "Trainable params: 486,804\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nadam = tf.keras.optimizers.Nadam(\n",
        "    learning_rate=1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Nadam\"\n",
        ")"
      ],
      "metadata": {
        "id": "Gc-YimqF4TBW"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adamax = tf.keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)"
      ],
      "metadata": {
        "id": "ho7RD9fBVGmX"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = tf.keras.optimizers.SGD(\n",
        "    learning_rate=0.01,\n",
        "    momentum=0.0,\n",
        "    nesterov=False,\n",
        "    name='SGD',\n",
        ")"
      ],
      "metadata": {
        "id": "QzwfU5NdVK0f"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adam =  keras.optimizers.Adam(lr = 1e-3)"
      ],
      "metadata": {
        "id": "Q7vCTvZQ4XKY"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "        loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "        optimizer = adam,\n",
        "        metrics = ['acc'],\n",
        ")"
      ],
      "metadata": {
        "id": "PNubZ416Sviu"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "MwlAQESPeIOd"
      },
      "outputs": [],
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', patience = 2, verbose = 1, factor = 0.5, min_lr = 1e-7)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(\"best_model.hdf5\", monitor='loss', verbose=1,\n",
        "    save_best_only=True, mode='auto', period=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ssxru6PafEl",
        "outputId": "b83941e3-269d-4639-f1c0-22615c0a2316"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ob_iP5OgeIMD",
        "outputId": "cb5beca6-e85d-4300-e35a-25c0c882922b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 1.2982 - acc: 0.6037\n",
            "Epoch 1: loss improved from inf to 1.29822, saving model to best_model.hdf5\n",
            "1299/1299 [==============================] - 106s 81ms/step - loss: 1.2982 - acc: 0.6037 - val_loss: 0.5070 - val_acc: 0.8632 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.4269 - acc: 0.8868\n",
            "Epoch 2: loss improved from 1.29822 to 0.42695, saving model to best_model.hdf5\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.4269 - acc: 0.8868 - val_loss: 0.3613 - val_acc: 0.9086 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.3196 - acc: 0.9179\n",
            "Epoch 3: loss improved from 0.42695 to 0.31949, saving model to best_model.hdf5\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.3195 - acc: 0.9179 - val_loss: 0.3703 - val_acc: 0.9079 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.2688 - acc: 0.9324\n",
            "Epoch 4: loss improved from 0.31949 to 0.26887, saving model to best_model.hdf5\n",
            "1299/1299 [==============================] - 25s 19ms/step - loss: 0.2689 - acc: 0.9324 - val_loss: 0.3063 - val_acc: 0.9295 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.2414 - acc: 0.9369\n",
            "Epoch 5: loss improved from 0.26887 to 0.24123, saving model to best_model.hdf5\n",
            "1299/1299 [==============================] - 25s 20ms/step - loss: 0.2412 - acc: 0.9369 - val_loss: 0.2939 - val_acc: 0.9344 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.2246 - acc: 0.9422\n",
            "Epoch 6: loss improved from 0.24123 to 0.22450, saving model to best_model.hdf5\n",
            "1299/1299 [==============================] - 25s 19ms/step - loss: 0.2245 - acc: 0.9423 - val_loss: 0.2582 - val_acc: 0.9403 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.2052 - acc: 0.9473\n",
            "Epoch 7: loss improved from 0.22450 to 0.20521, saving model to best_model.hdf5\n",
            "1299/1299 [==============================] - 25s 19ms/step - loss: 0.2052 - acc: 0.9473 - val_loss: 0.2698 - val_acc: 0.9432 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.1958 - acc: 0.9497\n",
            "Epoch 8: loss improved from 0.20521 to 0.19602, saving model to best_model.hdf5\n",
            "1299/1299 [==============================] - 25s 20ms/step - loss: 0.1960 - acc: 0.9497 - val_loss: 0.2506 - val_acc: 0.9452 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.1913 - acc: 0.9493\n",
            "Epoch 9: loss improved from 0.19602 to 0.19144, saving model to best_model.hdf5\n",
            "1299/1299 [==============================] - 25s 19ms/step - loss: 0.1914 - acc: 0.9492 - val_loss: 0.2646 - val_acc: 0.9453 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.1879 - acc: 0.9518\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 10: loss improved from 0.19144 to 0.18783, saving model to best_model.hdf5\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.1878 - acc: 0.9518 - val_loss: 0.2559 - val_acc: 0.9422 - lr: 0.0010\n",
            "Epoch 11/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.1242 - acc: 0.9679\n",
            "Epoch 11: loss improved from 0.18783 to 0.12416, saving model to best_model.hdf5\n",
            "1299/1299 [==============================] - 27s 21ms/step - loss: 0.1242 - acc: 0.9679 - val_loss: 0.2287 - val_acc: 0.9514 - lr: 5.0000e-04\n",
            "Epoch 12/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.1070 - acc: 0.9707\n",
            "Epoch 12: loss improved from 0.12416 to 0.10689, saving model to best_model.hdf5\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.1069 - acc: 0.9707 - val_loss: 0.2434 - val_acc: 0.9512 - lr: 5.0000e-04\n",
            "Epoch 13/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.1045 - acc: 0.9715\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 13: loss improved from 0.10689 to 0.10446, saving model to best_model.hdf5\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.1045 - acc: 0.9715 - val_loss: 0.2405 - val_acc: 0.9517 - lr: 5.0000e-04\n",
            "Epoch 14/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.0786 - acc: 0.9780\n",
            "Epoch 14: loss improved from 0.10446 to 0.07859, saving model to best_model.hdf5\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0786 - acc: 0.9780 - val_loss: 0.2309 - val_acc: 0.9559 - lr: 2.5000e-04\n",
            "Epoch 15/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9816\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 15: loss improved from 0.07859 to 0.06311, saving model to best_model.hdf5\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0631 - acc: 0.9816 - val_loss: 0.2461 - val_acc: 0.9571 - lr: 2.5000e-04\n",
            "Epoch 16/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.0489 - acc: 0.9849\n",
            "Epoch 16: loss improved from 0.06311 to 0.04887, saving model to best_model.hdf5\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0489 - acc: 0.9849 - val_loss: 0.2544 - val_acc: 0.9577 - lr: 1.2500e-04\n",
            "Epoch 17/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9873\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 17: loss improved from 0.04887 to 0.04239, saving model to best_model.hdf5\n",
            "1299/1299 [==============================] - 54s 42ms/step - loss: 0.0424 - acc: 0.9872 - val_loss: 0.2616 - val_acc: 0.9560 - lr: 1.2500e-04\n",
            "Epoch 18/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9883\n",
            "Epoch 18: loss improved from 0.04239 to 0.03710, saving model to best_model.hdf5\n",
            "1299/1299 [==============================] - 27s 21ms/step - loss: 0.0371 - acc: 0.9883 - val_loss: 0.2613 - val_acc: 0.9586 - lr: 6.2500e-05\n",
            "Epoch 19/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.0330 - acc: 0.9902\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\n",
            "Epoch 19: loss improved from 0.03710 to 0.03302, saving model to best_model.hdf5\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0330 - acc: 0.9902 - val_loss: 0.2726 - val_acc: 0.9592 - lr: 6.2500e-05\n",
            "Epoch 20/30\n",
            "1296/1299 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9909\n",
            "Epoch 20: loss improved from 0.03302 to 0.02901, saving model to best_model.hdf5\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0290 - acc: 0.9909 - val_loss: 0.2784 - val_acc: 0.9587 - lr: 3.1250e-05\n",
            "Epoch 21/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.0286 - acc: 0.9911\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\n",
            "Epoch 21: loss improved from 0.02901 to 0.02860, saving model to best_model.hdf5\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0286 - acc: 0.9911 - val_loss: 0.2839 - val_acc: 0.9590 - lr: 3.1250e-05\n",
            "Epoch 22/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9906\n",
            "Epoch 22: loss improved from 0.02860 to 0.02829, saving model to best_model.hdf5\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0283 - acc: 0.9906 - val_loss: 0.2823 - val_acc: 0.9594 - lr: 1.5625e-05\n",
            "Epoch 23/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.0253 - acc: 0.9917\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\n",
            "Epoch 23: loss improved from 0.02829 to 0.02528, saving model to best_model.hdf5\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0253 - acc: 0.9917 - val_loss: 0.2814 - val_acc: 0.9581 - lr: 1.5625e-05\n",
            "Epoch 24/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.0260 - acc: 0.9914\n",
            "Epoch 24: loss did not improve from 0.02528\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0260 - acc: 0.9914 - val_loss: 0.2813 - val_acc: 0.9593 - lr: 7.8125e-06\n",
            "Epoch 25/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.0258 - acc: 0.9920\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "\n",
            "Epoch 25: loss did not improve from 0.02528\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0258 - acc: 0.9920 - val_loss: 0.2824 - val_acc: 0.9588 - lr: 7.8125e-06\n",
            "Epoch 26/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9917\n",
            "Epoch 26: loss improved from 0.02528 to 0.02514, saving model to best_model.hdf5\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0251 - acc: 0.9917 - val_loss: 0.2825 - val_acc: 0.9589 - lr: 3.9063e-06\n",
            "Epoch 27/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.0250 - acc: 0.9923\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
            "\n",
            "Epoch 27: loss improved from 0.02514 to 0.02496, saving model to best_model.hdf5\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0250 - acc: 0.9923 - val_loss: 0.2834 - val_acc: 0.9591 - lr: 3.9063e-06\n",
            "Epoch 28/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.0256 - acc: 0.9920\n",
            "Epoch 28: loss did not improve from 0.02496\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0256 - acc: 0.9920 - val_loss: 0.2836 - val_acc: 0.9589 - lr: 1.9531e-06\n",
            "Epoch 29/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9920\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
            "\n",
            "Epoch 29: loss improved from 0.02496 to 0.02447, saving model to best_model.hdf5\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0245 - acc: 0.9920 - val_loss: 0.2838 - val_acc: 0.9586 - lr: 1.9531e-06\n",
            "Epoch 30/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.0263 - acc: 0.9918\n",
            "Epoch 30: loss did not improve from 0.02447\n",
            "1299/1299 [==============================] - 26s 20ms/step - loss: 0.0263 - acc: 0.9918 - val_loss: 0.2840 - val_acc: 0.9589 - lr: 9.7656e-07\n"
          ]
        }
      ],
      "source": [
        "classifier = model.fit(train_ds, batch_size = batch_size, \n",
        "                                 epochs = 30,\n",
        "                                 callbacks=[reduce_lr, checkpoint],\n",
        "                                 validation_data = val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ghprZPhjGt4K"
      },
      "outputs": [],
      "source": [
        "model.save('/content/gdrive/MyDrive/30-epoch-val-acc-9589-lr-1e-3-two-dropout-2e-1-batch-32-adam.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data Augmentation**\n"
      ],
      "metadata": {
        "id": "c1fWmsuFZG65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "   rescale=1.0 / 255,\n",
        "   rotation_range=30,\n",
        "   width_shift_range=0.2,\n",
        "   height_shift_range=0.2,\n",
        "   vertical_flip=True,\n",
        ")"
      ],
      "metadata": {
        "id": "XERb7b_DO3jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EavxErWdZxYL",
        "outputId": "ffd6a80a-f1f9-46e3-b7cc-228ea6efb62d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 51952 images belonging to 20 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjIuEERLdM2a",
        "outputId": "a443ce00-246c-4668-807e-6f100051515a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.preprocessing.image.DirectoryIterator at 0x7f843b0df910>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "   rescale=1.0 / 255,\n",
        "   rotation_range=30,\n",
        "   width_shift_range=0.2,\n",
        "   height_shift_range=0.2,\n",
        "   vertical_flip=True,\n",
        ")"
      ],
      "metadata": {
        "id": "Nqk5FL0kZ6xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    directory=data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSrDjjkFZ-fW",
        "outputId": "f4669079-7f85-4f2b-844d-cb105e6c6762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 51952 images belonging to 20 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "   rescale=1.0 / 255,\n",
        "   rotation_range=30,\n",
        "   width_shift_range=0.2,\n",
        "   height_shift_range=0.2,\n",
        "   vertical_flip=True,\n",
        ")"
      ],
      "metadata": {
        "id": "Mgp7VGLnZ-dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory=data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=1,\n",
        "    class_mode=None,\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOP6e6CtZ-bE",
        "outputId": "e56cc77c-2574-4e83-9f98-8588981c1a01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 51952 images belonging to 20 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "            keras.Input(shape = (32, 32, 1)),\n",
        "            layers.Conv2D(32, 3, padding = 'same', activation = 'relu', name=\"Conv1\"),\n",
        "            layers.Conv2D(32, 3, padding = 'same', activation = 'relu', name=\"Conv2\"),\n",
        "            layers.Conv2D(32, 3, padding = 'same', activation = 'relu', name=\"Conv3\"),\n",
        "            layers.MaxPooling2D(name=\"Maxpool1\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv4\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv5\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv6\"),\n",
        "            layers.MaxPooling2D(name=\"Maxpool2\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv7\"),\n",
        "            layers.Conv2D(128, 3, padding = 'same', activation = 'relu', name=\"Conv8\"),\n",
        "            layers.Flatten(name=\"Flatten1\"),\n",
        "            layers.Dense(128, activation = 'relu', name=\"Dense1\"),\n",
        "            layers.Dense(20, activation = 'softmax', name=\"Dense2\"),\n",
        "])"
      ],
      "metadata": {
        "id": "xC5W6R-Wm1TP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adam =  keras.optimizers.Adam(lr = 1e-3)"
      ],
      "metadata": {
        "id": "2V05ebCknN01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "        loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "        optimizer = adam,\n",
        "        metrics = ['acc'],\n",
        ")"
      ],
      "metadata": {
        "id": "-4ZAIXSfnVNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', patience = 2, verbose = 1, factor = 0.5, min_lr = 1e-7)"
      ],
      "metadata": {
        "id": "p9pPVB31oyYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size"
      ],
      "metadata": {
        "id": "IfwxKkEinX1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = model.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    epochs=10\n",
        "                    callbacks=[reduce_lr]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iehx7HH9Z-Xj",
        "outputId": "eb3e0751-275c-4412-bc8b-1a0cd72bfadb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-f123216d65bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m classifier = model.fit_generator(generator=train_generator,\n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0;31m# steps_per_epoch=STEP_SIZE_TRAIN,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0;31m# validation_data=valid_generator,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0;31m# validation_steps=STEP_SIZE_VALID,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0;31m# epochs=10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2221\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2223\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2225\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n      handler_func(fileobj, events)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n      self._handle_recv()\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n      self._run_callback(callback, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n      callback(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n      return self.dispatch_shell(stream, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n      handler(stream, idents, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n      user_expressions, allow_stdin)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n      if self.run_code(code, result):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-21-429412f5a179>\", line 5, in <module>\n      epochs=10,\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 2223, in fit_generator\n      initial_epoch=initial_epoch)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 919, in compute_loss\n      y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1863, in sparse_categorical_crossentropy\n      y_true, y_pred, from_logits=from_logits, axis=axis)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5203, in sparse_categorical_crossentropy\n      labels=target, logits=output)\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [32,20] and labels shape [640]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_1311]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate_generator(generator=valid_generator,\n",
        "steps=STEP_SIZE_VALID)"
      ],
      "metadata": {
        "id": "wc94swvWZ-UB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_v5TAXFmZ-Qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hdAamlvDZ-Nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "b6KnbA9sYK4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00pV25MsvP1I"
      },
      "source": [
        "# Pytorch Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aW4pU14TULpi"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2qqtnBveIKU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5o5S2yLeIFa"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Resize([32,32]),\n",
        "    #  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "path = \"/content/gdrive/MyDrive/PreProcessDataset\"\n",
        "batch_size = 128\n",
        "\n",
        "trainset = torchvision.datasets.ImageFolder(path, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG4uwy70eICg"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.fc1 = nn.Linear(128 * 8 * 8, 128)\n",
        "        self.fc2 = nn.Linear(128, 20)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = torch.flatten(x, 1) \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.softmax(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "net.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWo1XwabeH_p"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsOkONcSeH8Z"
      },
      "outputs": [],
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 10 == 9:    \n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 10:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhjbEXNgMnMU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "c1fWmsuFZG65",
        "00pV25MsvP1I"
      ],
      "name": "Handwritten Amharic Digit Recognition Using Deep Learning.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
