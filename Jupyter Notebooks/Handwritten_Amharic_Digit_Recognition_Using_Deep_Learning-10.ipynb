{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mukerem/AmharicHandwrittenDigitRecognitionCNN/blob/main/Handwritten_Amharic_Digit_Recognition_Using_Deep_Learning-10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "29kuFJREaKYO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4487557d-5e86-4b85-cfd6-3629402bd85f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceCPcifFah1-"
      },
      "source": [
        "# **Load library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmIQsuCTbSBd"
      },
      "outputs": [],
      "source": [
        "# !unzip '/content/gdrive/MyDrive/PreProcessV1.zip' -d \"/content/gdrive/MyDrive/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UcKozwcMZzr6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "\n",
        "config = tf.compat.v1.ConfigProto( device_count = {'GPU': 1 , 'CPU': 56} ) \n",
        "sess = tf.compat.v1.Session(config=config) \n",
        "K.set_session(sess)\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaJv2RwyRfCN",
        "outputId": "c9355ad4-338f-4366-ac2c-229a1194591e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/PreProcessV1\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive/PreProcessV1/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "i0pycJHOZS1n"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "img_height = 32\n",
        "img_width = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QPzXdMv3cE5M"
      },
      "outputs": [],
      "source": [
        "data_dir = \"/content/gdrive/MyDrive/PreProcessV1/\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **keras**\n"
      ],
      "metadata": {
        "id": "sV3b0cetmmDq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9pKCR0DcEtS",
        "outputId": "c69f7c54-4cbb-4f73-ba4d-b41e7c90c2c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 51952 files belonging to 20 classes.\n",
            "Using 41562 files for training.\n"
          ]
        }
      ],
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  color_mode=\"grayscale\",\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53UWblhpdZ95",
        "outputId": "824a9d4a-abf2-4dc8-a8b0-997e8c01c38c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 51952 files belonging to 20 classes.\n",
            "Using 10390 files for validation.\n"
          ]
        }
      ],
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  color_mode=\"grayscale\",\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "CzBg_kpbeIVB"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "            keras.Input(shape = (32, 32, 1)),\n",
        "            layers.Conv2D(32, 3, padding = 'same', activation = 'relu', name=\"Conv1\"),\n",
        "            layers.Conv2D(32, 3, padding = 'same', activation = 'relu', name=\"Conv2\"),\n",
        "            layers.Conv2D(32, 3, padding = 'same', activation = 'relu', name=\"Conv3\"),\n",
        "            layers.MaxPooling2D(name=\"Maxpool1\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv4\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv5\"),\n",
        "            layers.MaxPooling2D(name=\"Maxpool3\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv6\"),\n",
        "            layers.MaxPooling2D(name=\"Maxpool4\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv7\"),\n",
        "            layers.MaxPooling2D(name=\"Maxpool5\"),\n",
        "            layers.Conv2D(128, 3, padding = 'same', activation = 'relu', name=\"Conv8\"),\n",
        "            layers.Flatten(name=\"Flatten1\"),\n",
        "            layers.Dense(128, activation = 'relu', name=\"Dense1\"),\n",
        "            layers.Dense(20, activation = 'softmax', name=\"Dense2\"),\n",
        "])"
      ],
      "metadata": {
        "id": "piJRCwqKm_vm"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APq2vCdU4kV8",
        "outputId": "c0d2d858-6d02-4ff5-a955-5b2be1ada893"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Conv1 (Conv2D)              (None, 32, 32, 32)        320       \n",
            "                                                                 \n",
            " Conv2 (Conv2D)              (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " Conv3 (Conv2D)              (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " Maxpool1 (MaxPooling2D)     (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " Conv4 (Conv2D)              (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " Conv5 (Conv2D)              (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " Maxpool3 (MaxPooling2D)     (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " Conv6 (Conv2D)              (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " Maxpool4 (MaxPooling2D)     (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " Conv7 (Conv2D)              (None, 4, 4, 64)          36928     \n",
            "                                                                 \n",
            " Maxpool5 (MaxPooling2D)     (None, 2, 2, 64)          0         \n",
            "                                                                 \n",
            " Conv8 (Conv2D)              (None, 2, 2, 128)         73856     \n",
            "                                                                 \n",
            " Flatten1 (Flatten)          (None, 512)               0         \n",
            "                                                                 \n",
            " Dense1 (Dense)              (None, 128)               65664     \n",
            "                                                                 \n",
            " Dense2 (Dense)              (None, 20)                2580      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,196\n",
            "Trainable params: 290,196\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nadam = tf.keras.optimizers.Nadam(\n",
        "    learning_rate=1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Nadam\"\n",
        ")"
      ],
      "metadata": {
        "id": "Gc-YimqF4TBW"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adamax = tf.keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)"
      ],
      "metadata": {
        "id": "ho7RD9fBVGmX"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = tf.keras.optimizers.SGD(\n",
        "    learning_rate=0.01,\n",
        "    momentum=0.0,\n",
        "    nesterov=False,\n",
        "    name='SGD',\n",
        ")"
      ],
      "metadata": {
        "id": "QzwfU5NdVK0f"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adam =  keras.optimizers.Adam(lr = 1e-3)"
      ],
      "metadata": {
        "id": "Q7vCTvZQ4XKY"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "        loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "        optimizer = adam,\n",
        "        metrics = ['acc'],\n",
        ")"
      ],
      "metadata": {
        "id": "PNubZ416Sviu"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "MwlAQESPeIOd"
      },
      "outputs": [],
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', patience = 2, verbose = 1, factor = 0.5, min_lr = 1e-7)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(\"best_model.hdf5\", monitor='loss', verbose=1,\n",
        "    save_best_only=True, mode='auto', period=1)"
      ],
      "metadata": {
        "id": "9ssxru6PafEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ob_iP5OgeIMD",
        "outputId": "33886f95-84b8-404b-e66a-a1be14c856d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1299/1299 [==============================] - 23s 17ms/step - loss: 1.1755 - acc: 0.6430 - val_loss: 0.5131 - val_acc: 0.8624 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "1299/1299 [==============================] - 22s 17ms/step - loss: 0.3673 - acc: 0.9035 - val_loss: 0.4152 - val_acc: 0.8920 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "1299/1299 [==============================] - 22s 17ms/step - loss: 0.2749 - acc: 0.9290 - val_loss: 0.3361 - val_acc: 0.9189 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "1299/1299 [==============================] - 22s 17ms/step - loss: 0.2329 - acc: 0.9416 - val_loss: 0.4395 - val_acc: 0.9090 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "1297/1299 [============================>.] - ETA: 0s - loss: 0.2047 - acc: 0.9476\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "1299/1299 [==============================] - 22s 17ms/step - loss: 0.2047 - acc: 0.9476 - val_loss: 0.3741 - val_acc: 0.9265 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "1299/1299 [==============================] - 22s 17ms/step - loss: 0.1257 - acc: 0.9673 - val_loss: 0.3383 - val_acc: 0.9356 - lr: 5.0000e-04\n",
            "Epoch 7/30\n",
            "1296/1299 [============================>.] - ETA: 0s - loss: 0.0922 - acc: 0.9753\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "1299/1299 [==============================] - 22s 17ms/step - loss: 0.0923 - acc: 0.9753 - val_loss: 0.3730 - val_acc: 0.9325 - lr: 5.0000e-04\n",
            "Epoch 8/30\n",
            "1299/1299 [==============================] - 22s 17ms/step - loss: 0.0529 - acc: 0.9851 - val_loss: 0.3533 - val_acc: 0.9431 - lr: 2.5000e-04\n",
            "Epoch 9/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9901\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "1299/1299 [==============================] - 22s 17ms/step - loss: 0.0329 - acc: 0.9901 - val_loss: 0.4259 - val_acc: 0.9375 - lr: 2.5000e-04\n",
            "Epoch 10/30\n",
            "1299/1299 [==============================] - 22s 17ms/step - loss: 0.0191 - acc: 0.9938 - val_loss: 0.4778 - val_acc: 0.9423 - lr: 1.2500e-04\n",
            "Epoch 11/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9964\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "1299/1299 [==============================] - 22s 17ms/step - loss: 0.0115 - acc: 0.9964 - val_loss: 0.5608 - val_acc: 0.9396 - lr: 1.2500e-04\n",
            "Epoch 12/30\n",
            "1299/1299 [==============================] - 22s 17ms/step - loss: 0.0068 - acc: 0.9980 - val_loss: 0.5988 - val_acc: 0.9447 - lr: 6.2500e-05\n",
            "Epoch 13/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9986\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "1299/1299 [==============================] - 22s 17ms/step - loss: 0.0045 - acc: 0.9986 - val_loss: 0.6713 - val_acc: 0.9441 - lr: 6.2500e-05\n",
            "Epoch 14/30\n",
            "1299/1299 [==============================] - 22s 17ms/step - loss: 0.0036 - acc: 0.9989 - val_loss: 0.7152 - val_acc: 0.9449 - lr: 3.1250e-05\n",
            "Epoch 15/30\n",
            "1299/1299 [==============================] - ETA: 0s - loss: 0.0032 - acc: 0.9989\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "1299/1299 [==============================] - 22s 17ms/step - loss: 0.0032 - acc: 0.9989 - val_loss: 0.7716 - val_acc: 0.9449 - lr: 3.1250e-05\n",
            "Epoch 16/30\n",
            "1299/1299 [==============================] - 23s 18ms/step - loss: 0.0029 - acc: 0.9990 - val_loss: 0.7999 - val_acc: 0.9441 - lr: 1.5625e-05\n",
            "Epoch 17/30\n",
            "1296/1299 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9991\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "1299/1299 [==============================] - 22s 17ms/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.8485 - val_acc: 0.9447 - lr: 1.5625e-05\n",
            "Epoch 18/30\n",
            "1299/1299 [==============================] - 22s 17ms/step - loss: 0.0026 - acc: 0.9991 - val_loss: 0.8733 - val_acc: 0.9449 - lr: 7.8125e-06\n",
            "Epoch 19/30\n",
            "1296/1299 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9992\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "1299/1299 [==============================] - 22s 17ms/step - loss: 0.0026 - acc: 0.9992 - val_loss: 0.9067 - val_acc: 0.9449 - lr: 7.8125e-06\n",
            "Epoch 20/30\n",
            "1299/1299 [==============================] - 22s 17ms/step - loss: 0.0025 - acc: 0.9992 - val_loss: 0.9252 - val_acc: 0.9448 - lr: 3.9063e-06\n",
            "Epoch 21/30\n",
            "1296/1299 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9992\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
            "1299/1299 [==============================] - 22s 17ms/step - loss: 0.0025 - acc: 0.9992 - val_loss: 0.9460 - val_acc: 0.9447 - lr: 3.9063e-06\n",
            "Epoch 22/30\n",
            "1299/1299 [==============================] - 22s 17ms/step - loss: 0.0024 - acc: 0.9992 - val_loss: 0.9559 - val_acc: 0.9445 - lr: 1.9531e-06\n",
            "Epoch 23/30\n",
            "1296/1299 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9992\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
            "1299/1299 [==============================] - 22s 17ms/step - loss: 0.0024 - acc: 0.9992 - val_loss: 0.9673 - val_acc: 0.9446 - lr: 1.9531e-06\n",
            "Epoch 24/30\n",
            "1299/1299 [==============================] - 22s 17ms/step - loss: 0.0024 - acc: 0.9992 - val_loss: 0.9725 - val_acc: 0.9446 - lr: 9.7656e-07\n",
            "Epoch 25/30\n",
            "1298/1299 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9992\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
            "1299/1299 [==============================] - 22s 17ms/step - loss: 0.0024 - acc: 0.9992 - val_loss: 0.9786 - val_acc: 0.9445 - lr: 9.7656e-07\n",
            "Epoch 26/30\n",
            "1299/1299 [==============================] - 22s 17ms/step - loss: 0.0024 - acc: 0.9992 - val_loss: 0.9812 - val_acc: 0.9445 - lr: 4.8828e-07\n",
            "Epoch 27/30\n",
            "1296/1299 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9992\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
            "1299/1299 [==============================] - 24s 18ms/step - loss: 0.0024 - acc: 0.9992 - val_loss: 0.9843 - val_acc: 0.9445 - lr: 4.8828e-07\n",
            "Epoch 28/30\n",
            "1299/1299 [==============================] - 23s 18ms/step - loss: 0.0024 - acc: 0.9992 - val_loss: 0.9856 - val_acc: 0.9445 - lr: 2.4414e-07\n",
            "Epoch 29/30\n",
            "1296/1299 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9992\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
            "1299/1299 [==============================] - 22s 17ms/step - loss: 0.0024 - acc: 0.9992 - val_loss: 0.9871 - val_acc: 0.9444 - lr: 2.4414e-07\n",
            "Epoch 30/30\n",
            "1299/1299 [==============================] - 23s 18ms/step - loss: 0.0024 - acc: 0.9992 - val_loss: 0.9878 - val_acc: 0.9444 - lr: 1.2207e-07\n"
          ]
        }
      ],
      "source": [
        "classifier = model.fit(train_ds, batch_size = batch_size, \n",
        "                                 epochs = 30,\n",
        "                                 callbacks=[reduce_lr, checkpoint],\n",
        "                                 validation_data = val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ghprZPhjGt4K"
      },
      "outputs": [],
      "source": [
        "# model.save('/content/gdrive/MyDrive/30-epoch-val-acc-95-lr-1e-3-batch-32-adam.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data Augmentation**\n"
      ],
      "metadata": {
        "id": "c1fWmsuFZG65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "   rescale=1.0 / 255,\n",
        "   rotation_range=30,\n",
        "   width_shift_range=0.2,\n",
        "   height_shift_range=0.2,\n",
        "   vertical_flip=True,\n",
        ")"
      ],
      "metadata": {
        "id": "XERb7b_DO3jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EavxErWdZxYL",
        "outputId": "ffd6a80a-f1f9-46e3-b7cc-228ea6efb62d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 51952 images belonging to 20 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjIuEERLdM2a",
        "outputId": "a443ce00-246c-4668-807e-6f100051515a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.preprocessing.image.DirectoryIterator at 0x7f843b0df910>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "   rescale=1.0 / 255,\n",
        "   rotation_range=30,\n",
        "   width_shift_range=0.2,\n",
        "   height_shift_range=0.2,\n",
        "   vertical_flip=True,\n",
        ")"
      ],
      "metadata": {
        "id": "Nqk5FL0kZ6xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    directory=data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSrDjjkFZ-fW",
        "outputId": "f4669079-7f85-4f2b-844d-cb105e6c6762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 51952 images belonging to 20 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "   rescale=1.0 / 255,\n",
        "   rotation_range=30,\n",
        "   width_shift_range=0.2,\n",
        "   height_shift_range=0.2,\n",
        "   vertical_flip=True,\n",
        ")"
      ],
      "metadata": {
        "id": "Mgp7VGLnZ-dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory=data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=1,\n",
        "    class_mode=None,\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOP6e6CtZ-bE",
        "outputId": "e56cc77c-2574-4e83-9f98-8588981c1a01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 51952 images belonging to 20 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "            keras.Input(shape = (32, 32, 1)),\n",
        "            layers.Conv2D(32, 3, padding = 'same', activation = 'relu', name=\"Conv1\"),\n",
        "            layers.Conv2D(32, 3, padding = 'same', activation = 'relu', name=\"Conv2\"),\n",
        "            layers.Conv2D(32, 3, padding = 'same', activation = 'relu', name=\"Conv3\"),\n",
        "            layers.MaxPooling2D(name=\"Maxpool1\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv4\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv5\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv6\"),\n",
        "            layers.MaxPooling2D(name=\"Maxpool2\"),\n",
        "            layers.Conv2D(64, 3, padding = 'same', activation = 'relu', name=\"Conv7\"),\n",
        "            layers.Conv2D(128, 3, padding = 'same', activation = 'relu', name=\"Conv8\"),\n",
        "            layers.Flatten(name=\"Flatten1\"),\n",
        "            layers.Dense(128, activation = 'relu', name=\"Dense1\"),\n",
        "            layers.Dense(20, activation = 'softmax', name=\"Dense2\"),\n",
        "])"
      ],
      "metadata": {
        "id": "xC5W6R-Wm1TP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adam =  keras.optimizers.Adam(lr = 1e-3)"
      ],
      "metadata": {
        "id": "2V05ebCknN01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "        loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "        optimizer = adam,\n",
        "        metrics = ['acc'],\n",
        ")"
      ],
      "metadata": {
        "id": "-4ZAIXSfnVNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', patience = 2, verbose = 1, factor = 0.5, min_lr = 1e-7)"
      ],
      "metadata": {
        "id": "p9pPVB31oyYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size"
      ],
      "metadata": {
        "id": "IfwxKkEinX1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = model.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    epochs=10\n",
        "                    callbacks=[reduce_lr]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iehx7HH9Z-Xj",
        "outputId": "eb3e0751-275c-4412-bc8b-1a0cd72bfadb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-f123216d65bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m classifier = model.fit_generator(generator=train_generator,\n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0;31m# steps_per_epoch=STEP_SIZE_TRAIN,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0;31m# validation_data=valid_generator,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0;31m# validation_steps=STEP_SIZE_VALID,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0;31m# epochs=10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2221\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2223\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2225\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n      handler_func(fileobj, events)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n      self._handle_recv()\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n      self._run_callback(callback, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n      callback(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n      return self.dispatch_shell(stream, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n      handler(stream, idents, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n      user_expressions, allow_stdin)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n      if self.run_code(code, result):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-21-429412f5a179>\", line 5, in <module>\n      epochs=10,\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 2223, in fit_generator\n      initial_epoch=initial_epoch)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 919, in compute_loss\n      y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1863, in sparse_categorical_crossentropy\n      y_true, y_pred, from_logits=from_logits, axis=axis)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5203, in sparse_categorical_crossentropy\n      labels=target, logits=output)\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [32,20] and labels shape [640]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_1311]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate_generator(generator=valid_generator,\n",
        "steps=STEP_SIZE_VALID)"
      ],
      "metadata": {
        "id": "wc94swvWZ-UB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_v5TAXFmZ-Qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hdAamlvDZ-Nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "b6KnbA9sYK4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00pV25MsvP1I"
      },
      "source": [
        "# Pytorch Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aW4pU14TULpi"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2qqtnBveIKU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5o5S2yLeIFa"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Resize([32,32]),\n",
        "    #  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "path = \"/content/gdrive/MyDrive/PreProcessDataset\"\n",
        "batch_size = 128\n",
        "\n",
        "trainset = torchvision.datasets.ImageFolder(path, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG4uwy70eICg"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.fc1 = nn.Linear(128 * 8 * 8, 128)\n",
        "        self.fc2 = nn.Linear(128, 20)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = torch.flatten(x, 1) \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.softmax(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "net.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWo1XwabeH_p"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsOkONcSeH8Z"
      },
      "outputs": [],
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 10 == 9:    \n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 10:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhjbEXNgMnMU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "c1fWmsuFZG65",
        "00pV25MsvP1I"
      ],
      "name": "Handwritten Amharic Digit Recognition Using Deep Learning.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}